{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_name = glob.glob('../article/headline_noun_keyword*')\n",
    "\n",
    "keyword_df = []\n",
    "for file in file_name:\n",
    "    df = pd.read_pickle(file)\n",
    "    keyword_df.append(df)\n",
    "\n",
    "keyword_all = pd.concat(keyword_df, ignore_index = True)\n",
    "all_article = keyword_all[keyword_all['week'] <= 807]\n",
    "all_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "start_date = date(2006,1,1)\n",
    "mh = date(2008,2,24)\n",
    "mb = date(2013,2,24)\n",
    "gh = date(2016,12,9)\n",
    "ga = date(2017,5,10) #황교안 대행\n",
    "ji = date(2022,5,9)\n",
    "mhw = (mh - start_date).days//7\n",
    "mbw = (mb - start_date).days//7\n",
    "ghw = (gh - start_date).days//7\n",
    "gaw = (ga - start_date).days//7\n",
    "jiw = (ji - start_date).days//7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = ['mh','mb','gh','ji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = {}\n",
    "time_range['mh'] = (0,mhw)\n",
    "time_range['mb'] = (mhw,mbw)\n",
    "time_range['gh'] = (mbw,ghw)\n",
    "#time_range['ga'] = (ghw,gaw)\n",
    "time_range['ji'] = (gaw,808)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_article = {}\n",
    "for g in gov:\n",
    "    week_s, week_e = time_range[g]\n",
    "    gov_article[g] = all_article[(all_article['week'] >= week_s) & (all_article['week'] < week_e)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_tokenized_data = {}\n",
    "for g in gov:\n",
    "    tokenized_data = []\n",
    "    for keyword in gov_article[g]['pos']:\n",
    "        tokenized_data.append(keyword)\n",
    "    gov_tokenized_data[g] = tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = {}\n",
    "\n",
    "for g in gov:\n",
    "    m = Word2Vec(sentences = gov_tokenized_data[g], window = 5, min_count = 100, workers = 4, sg = 1)\n",
    "    model[g] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gov:\n",
    "    print(model[g].wv.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_similar_up_origin = {}\n",
    "for g in gov:\n",
    "    similar_up_origin = [i[0] for i in model[g].wv.most_similar(\"상승\")]\n",
    "    similar_up_origin.append('상승')\n",
    "    gov_similar_up_origin[g] = similar_up_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_similar_up_expend = {}\n",
    "for g in gov:\n",
    "    similar_up_expend = [(suo,model[g].wv.similarity('상승',suo)) for suo in gov_similar_up_origin[g]]\n",
    "    for suo in gov_similar_up_origin[g]:\n",
    "        similar_suo = [i[0] for i in model[g].wv.most_similar(suo)]\n",
    "        for ssuo in similar_suo:\n",
    "            similar_up_expend.append((ssuo,model[g].wv.similarity('상승',ssuo)))\n",
    "    gov_similar_up_expend[g] = similar_up_expend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_similar_up_df = {}\n",
    "for g in gov:\n",
    "    gov_similar_up_expend[g] = list(set(gov_similar_up_expend[g]))\n",
    "    similar_up_df = pd.DataFrame(gov_similar_up_expend[g])\n",
    "    similar_up_df = similar_up_df.sort_values(by = 1, ascending = False,ignore_index = True)\n",
    "    similar_up_df.columns = ['keyword','similarity_with_상승']\n",
    "    gov_similar_up_df[g] = similar_up_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_similar_down_origin = {}\n",
    "for g in gov:\n",
    "    similar_down_origin = [i[0] for i in model[g].wv.most_similar(\"하락\")]\n",
    "    similar_down_origin.append('하락')\n",
    "    gov_similar_down_origin[g] = similar_down_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_similar_down_expend = {}\n",
    "for g in gov:\n",
    "    similar_down_expend = [(suo,model[g].wv.similarity('하락',suo)) for suo in gov_similar_down_origin[g]]\n",
    "    for suo in gov_similar_down_origin[g]:\n",
    "        similar_suo = [i[0] for i in model[g].wv.most_similar(suo)]\n",
    "        for ssuo in similar_suo:\n",
    "            similar_down_expend.append((ssuo,model[g].wv.similarity('하락',ssuo)))\n",
    "    gov_similar_down_expend[g] = similar_down_expend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_similar_down_df = {}\n",
    "for g in gov:\n",
    "    gov_similar_down_expend[g] = list(set(gov_similar_down_expend[g]))\n",
    "    similar_down_df = pd.DataFrame(gov_similar_down_expend[g])\n",
    "    similar_down_df = similar_down_df.sort_values(by = 1, ascending = False,ignore_index = True)\n",
    "    similar_down_df.columns = ['keyword','similarity_with_하락']\n",
    "    gov_similar_down_df[g] = similar_down_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 중복된 키워드 지우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_up_word = {}\n",
    "for g in gov:\n",
    "    up_word = []\n",
    "    _list = [i for i in gov_similar_up_df[g]['keyword']]\n",
    "    for i in gov_similar_up_df[g]['keyword']:\n",
    "        if i not in _list:\n",
    "            up_word.append(i)\n",
    "        if len(up_word) == 5:\n",
    "            break\n",
    "    gov_up_word[g] = up_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_down_word = {}\n",
    "for g in gov:\n",
    "    down_word = []\n",
    "    _list = [i for i in gov_similar_down_df[g]['keyword']]\n",
    "    for i in gov_similar_down_df[g]['keyword']:\n",
    "        if i not in _list:\n",
    "            down_word.append(i)\n",
    "        if len(down_word) == 5:\n",
    "            break\n",
    "    gov_down_word[g] = down_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 중복된 키워드가 up에 가까운지 down에 가까운지 확인하고 가까운 쪽으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_up_word = {}\n",
    "for g in gov:\n",
    "    up_word = []\n",
    "    _list = [i for i in gov_similar_down_df[g]['keyword']]\n",
    "    for i in gov_similar_up_df[g]['keyword']:\n",
    "        if i not in _list:\n",
    "            up_word.append(i)\n",
    "        else:\n",
    "            if float(gov_similar_up_df[g][gov_similar_up_df[g]['keyword'] == i]['similarity_with_상승']) >= float(gov_similar_down_df[g][gov_similar_down_df[g]['keyword'] == i]['similarity_with_하락']):\n",
    "                up_word.append(i)\n",
    "        if len(up_word) == 5:\n",
    "            break\n",
    "    gov_up_word[g] = up_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_down_word = {}\n",
    "for g in gov:\n",
    "    down_word = []\n",
    "    _list = [i for i in gov_similar_up_df[g]['keyword']]\n",
    "    for i in gov_similar_down_df[g]['keyword']:\n",
    "        if i not in _list:\n",
    "            down_word.append(i)\n",
    "        else:\n",
    "            if float(gov_similar_down_df[g][gov_similar_down_df[g]['keyword'] == i]['similarity_with_하락']) >= float(gov_similar_up_df[g][gov_similar_up_df[g]['keyword'] == i]['similarity_with_상승']):\n",
    "                down_word.append(i)\n",
    "        if len(down_word) == 5:\n",
    "            break\n",
    "    gov_down_word[g] = down_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None \n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "\n",
    "\n",
    "\"Creates and TSNE model and plots it\"\n",
    "\n",
    "gov_x = {}\n",
    "gov_y = {}\n",
    "gov_words = {}\n",
    "for g in gov:\n",
    "    labels = []\n",
    "    tokens = []\n",
    "    words = list(model[g].wv.index_to_key)\n",
    "    for word in words:\n",
    "        tokens.append(model[g].wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(24, 24)) \n",
    "    for i in range(len(x)):\n",
    "        if (labels[i] == '상승') or (labels[i] == '하락'):\n",
    "            plt.scatter(x[i],y[i], s = 100, color = 'r')\n",
    "        else:\n",
    "            plt.scatter(x[i],y[i], color = 'b')\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom', )\n",
    "    plt.savefig(f'../article/keyword_vector_{g}.png', dpi=300)\n",
    "    plt.show()\n",
    "    gov_x[g] = x\n",
    "    gov_y[g] = y\n",
    "    gov_words[g] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_index = []\n",
    "dw_index = []\n",
    "\n",
    "for uw in up_word:\n",
    "    uw_index.append(words.index(uw))\n",
    "    \n",
    "for dw in down_word:\n",
    "    dw_index.append(words.index(dw))\n",
    "    \n",
    "uw_vector = []\n",
    "dw_vector = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gov:\n",
    "    ui = words[g].index('상승')\n",
    "    di = words[g].index('하락')\n",
    "\n",
    "    print(f'{g} 상승 vector: ({x[g][ui]}, {y[g][ui]})')\n",
    "    print(f'{g} 하락 vector: ({x[g][di]}, {y[g][di]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
